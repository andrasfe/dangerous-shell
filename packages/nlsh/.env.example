# OpenRouter API Configuration
# Get your API key from: https://openrouter.ai/keys

OPENROUTER_API_KEY=your_api_key_here

# Model to use (see https://openrouter.ai/models for options)
OPENROUTER_MODEL=anthropic/claude-sonnet-4

# Voice input model (for speech-to-text)
OPENROUTER_VOICE_MODEL=google/gemini-2.5-flash-lite

# Local Model Configuration (LM Studio, Ollama, etc.)
# Set NLSH_LOCAL_MODEL=true to use a local model instead of OpenRouter
NLSH_LOCAL_MODEL=false

# Local model API URL (LM Studio default: http://localhost:1234/v1)
NLSH_LOCAL_URL=http://localhost:1234/v1

# Model name (optional - LM Studio uses the currently loaded model)
NLSH_LOCAL_MODEL_NAME=local-model

# Remote Execution Configuration
# Use SSH tunnel for security: ./tunnel.sh user@remote-host

# Connect to localhost (through SSH tunnel)
NLSH_REMOTE_HOST=127.0.0.1

# Remote server port
NLSH_REMOTE_PORT=8765

# Shared secret for HMAC authentication (must match server)
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
NLSH_SHARED_SECRET=your_shared_secret_here
