# OpenRouter API Configuration
# Get your API key from: https://openrouter.ai/keys

OPENROUTER_API_KEY=your_api_key_here

# Model to use (see https://openrouter.ai/models for options)
OPENROUTER_MODEL=anthropic/claude-sonnet-4

# Voice input model (for speech-to-text)
OPENROUTER_VOICE_MODEL=google/gemini-2.5-flash-lite

# Local Model Configuration (LM Studio, Ollama, etc.)
# Set NLSH_LOCAL_MODEL=true to use a local model instead of OpenRouter
NLSH_LOCAL_MODEL=false

# Local model API URL (LM Studio default: http://localhost:1234/v1)
NLSH_LOCAL_URL=http://localhost:1234/v1

# Model name (optional - LM Studio uses the currently loaded model)
NLSH_LOCAL_MODEL_NAME=local-model

# Remote Execution Configuration (optional)
# Set these to enable remote command execution via nlsh-remote

# Remote server hostname or IP address
NLSH_REMOTE_HOST=192.168.1.100

# Remote server port
NLSH_REMOTE_PORT=8765

# Shared secret for HMAC authentication (must match server)
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
NLSH_SHARED_SECRET=your_shared_secret_here

# SSL/TLS Configuration
# Enable SSL for secure WebSocket connection (wss://)
NLSH_SSL=false

# Verify SSL certificate (set to false for self-signed certs)
NLSH_SSL_VERIFY=true
